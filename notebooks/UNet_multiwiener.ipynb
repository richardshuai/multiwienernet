{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from src.model import *\n",
    "\n",
    "import io\n",
    "import json\n",
    "from os import path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dims = (648, 486)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_description = 'model_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "record_dir = path.join('..', 'data', model_description)\n",
    "train_dataset_files = glob.glob(path.join(record_dir, 'train', '*'))\n",
    "val_dataset_files = glob.glob(path.join(record_dir, 'validation', '*'))\n",
    "\n",
    "\n",
    "# Paths for saving/loading model weights, predictions\n",
    "base_path = path.join('..', 'models', model_description)\n",
    "model_weights_path = path.join(base_path, model_description)\n",
    "image_path = path.join(base_path, 'prediction-images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(base_path, exist_ok=True)\n",
    "os.makedirs(image_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = len(train_dataset_files)\n",
    "VAL_LENGTH = len(val_dataset_files)\n",
    "input_shape = (None, 648, 486, 1)\n",
    "\n",
    "obj_dims = (648, 486)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        'plane': tf.io.FixedLenFeature(obj_dims, tf.float32),\n",
    "        'sim': tf.io.FixedLenFeature(obj_dims, tf.float32)\n",
    "        \n",
    "    }\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    \n",
    "    plane = example['plane']\n",
    "\n",
    "    # Downsampling\n",
    "#     plane = tf.squeeze(tf.image.resize(plane[tf.newaxis, ..., tf.newaxis], [648, 486]))\n",
    "#     plane = plane[2:322, 2:242]\n",
    "    \n",
    "    plane_max = tf.reduce_max(plane)\n",
    "    plane_min = tf.reduce_min(plane)\n",
    "    plane = (plane - plane_min) / (plane_max - plane_min)  # Normalize values to [0, 1]\n",
    "\n",
    "    sim = example['sim']\n",
    "\n",
    "    # Downsampling\n",
    "#     sim = tf.squeeze(tf.image.resize(sim[tf.newaxis, ..., tf.newaxis], [648, 486]))\n",
    "\n",
    "    sim_max = tf.reduce_max(sim)\n",
    "    sim_min = tf.reduce_min(sim)\n",
    "    sim = (sim - sim_min) / (sim_max - sim_min)  # Normalize values to [0, 1]\n",
    "\n",
    "    # Expand to channel dimension\n",
    "    sim = sim[..., tf.newaxis]\n",
    "\n",
    "    \n",
    "    return sim, plane\n",
    "\n",
    "def create_dataset(filenames, batch_size):\n",
    "    \"\"\"\n",
    "    Takes in string array of filenames for TFRecord files containing samples.\n",
    "    Returns: TFRecordDataset with given batch size\n",
    "    \"\"\"\n",
    "    filenames = tf.random.shuffle(filenames)\n",
    "    raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    \n",
    "    dataset = raw_dataset.map(_parse_function)\n",
    "    dataset = dataset.shuffle(256)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "STEPS_PER_EPOCH = int(np.ceil(TRAIN_LENGTH / BATCH_SIZE))\n",
    "VAL_STEPS = int(np.ceil(VAL_LENGTH / BATCH_SIZE))\n",
    "\n",
    "train_dataset = create_dataset(train_dataset_files, BATCH_SIZE)\n",
    "val_dataset = create_dataset(val_dataset_files, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def scaled_mse_loss(y_actual,y_pred):\n",
    "    loss = K.square((y_actual-y_pred))\n",
    "    loss = K.sum(loss)\n",
    "    return loss\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def scaled_mse_loss(y_actual,y_pred):\n",
    "    loss = K.square((y_actual-y_pred))\n",
    "#     loss = K.sqrt(loss)\n",
    "    loss = K.sum(loss)\n",
    "    return loss\n",
    "\n",
    "def plot_image_tensorboard(epoch, logs):\n",
    "    # Create a plot to visualize image reconstruction progress\n",
    "    \n",
    "    # Call the model to get prediction\n",
    "    pred = model.predict(val_sample[0][0][np.newaxis])\n",
    "\n",
    "    # Create a mpl figure\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "    # Plot the prediction\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"prediction\")\n",
    "    plt.imshow(pred[0].astype(np.float32))\n",
    "    # Plot groundtruth\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"ground truth\")\n",
    "    plt.imshow(val_sample[1][0].numpy().astype(np.float32))\n",
    "    plot_image = plot_to_image(figure)\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Prediction vs Ground Truth\", plot_image, step=epoch)\n",
    "\n",
    "import datetime\n",
    "log_dir=os.path.join('logs', model_description + '-fit') + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=1000000)\n",
    "file_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "plot_image_tensorboard_cb = keras.callbacks.LambdaCallback(on_epoch_end=plot_image_tensorboard)\n",
    "\n",
    "# Save model after epochs\n",
    "checkpoint_cb = ModelCheckpoint(model_weights_path + '.e{epoch:03d}', monitor='val_loss', verbose=0, \n",
    "                             save_best_only=False, save_weights_only=True, mode='auto', \n",
    "                                save_freq=10*STEPS_PER_EPOCH)\n",
    "checkpoint_best_cb = ModelCheckpoint(model_weights_path + '.best', monitor='val_loss', verbose=0,\n",
    "                                    save_best_only=True, save_weights_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIMLoss(y_true, y_pred):\n",
    "    y_true = y_true[..., np.newaxis]\n",
    "    y_pred = y_pred[..., np.newaxis]\n",
    "    \n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps_path = '/home/rshuai/research/u-net-reconstruction/data/PSFs/processed/rank24_z0_ds2_normalized/comps.npy'\n",
    "weights_path = '/home/rshuai/research/u-net-reconstruction/data/PSFs/processed/rank24_z0_ds2_normalized/weights.npy'\n",
    "\n",
    "# Load in comps and weights\n",
    "h = np.load(comps_path)\n",
    "weights = np.load(weights_path)\n",
    "\n",
    "psf = tf.squeeze(tf.math.reduce_sum(h*weights, axis=0))\n",
    "psf = psf / tf.math.reduce_max(psf)\n",
    "K = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet multiwiener\n",
    "registered_psfs_path = '/home/rshuai/research/u-net-reconstruction/data/PSFs/9_psfs/psfs_Z1_1_9_registered.npy'\n",
    "\n",
    "psfs = np.load(registered_psfs_path).transpose([1, 2, 0])\n",
    "assert psfs.shape == (648, 486, 9)\n",
    "\n",
    "Ks = np.ones((1, 1, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central PSF is psf[4]\n",
    "psf = psfs[:, :, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample PSFs for downsampled inputs\n",
    "# psfs = tf.image.resize(psfs, [648//2, 486//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet_multiwiener_resize(648, 486, psfs, Ks, \n",
    "                         encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "                         center_cs=1024,\n",
    "                         decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "                         skip_connections=[True, True, True, True, True, False])\n",
    "\n",
    "# model = UNet_wiener(648, 486, psf, K, \n",
    "#                          encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "#                          center_cs=1024,\n",
    "#                          decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "#                          skip_connections=[True, True, True, True, True, False])\n",
    "\n",
    "# model = UNet(648, 486,\n",
    "#                  encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "#                  center_cs=1024,\n",
    "#                  decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "#                  skip_connections=[True, True, True, True, True, False])\n",
    "\n",
    "\n",
    "initial_learning_rate = 1e-4\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer=adam, loss=SSIMLoss, metrics=SSIMLoss)\n",
    "model.build((None, 648, 486, 1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sample = next(iter(val_dataset)) # Used for logging and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0.0001, patience=15, verbose=0,\n",
    "    mode='min', baseline=None, restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, \n",
    "          callbacks=[plot_image_tensorboard_cb, tensorboard_callback, checkpoint_cb, checkpoint_best_cb, earlystop_cb], \n",
    "          validation_data=val_dataset, validation_steps=VAL_STEPS)\n",
    "\n",
    "model.save_weights(model_weights_path, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Visualization, Timing Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DISPLAY = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet_2d()\n",
    "# model = UNet_2d_wiener(np.zeros_like(psf), K)\n",
    "# model = UNet_2d_wiener_components(comps, K)\n",
    "\n",
    "\n",
    "model = UNet_multiwiener_resize(648, 486, psfs, Ks, \n",
    "                         encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "                         center_cs=1024,\n",
    "                         decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "                         skip_connections=[True, True, True, True, True, False])\n",
    "\n",
    "# model = UNet_wiener(648, 486, psf, K, \n",
    "#                          encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "#                          center_cs=1024,\n",
    "#                          decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "#                          skip_connections=[True, True, True, True, True, False])\n",
    "\n",
    "# model = UNet(648, 486,\n",
    "#                  encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "#                  center_cs=1024,\n",
    "#                  decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "#                  skip_connections=[True, True, True, True, True, False])\n",
    "\n",
    "epoch = 'best'\n",
    "model.load_weights(model_weights_path + '.{}'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((NUM_DISPLAY, 648, 486))\n",
    "ground_truths = np.zeros((NUM_DISPLAY, 648, 486))\n",
    "\n",
    "# preds = np.zeros((NUM_DISPLAY, 640, 480))\n",
    "# ground_truths = np.zeros((NUM_DISPLAY, 640, 480))\n",
    "\n",
    "# preds = np.zeros((NUM_DISPLAY, 208, 124))\n",
    "# ground_truths = np.zeros((NUM_DISPLAY, 208, 124))\n",
    "sims = np.zeros((NUM_DISPLAY, 648, 486))\n",
    "# sims = np.zeros((NUM_DISPLAY, 648, 486, 6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With downsampled\n",
    "# preds = np.zeros((NUM_DISPLAY, 320, 240))\n",
    "# ground_truths = np.zeros((NUM_DISPLAY, 320, 240))\n",
    "# sims = np.zeros((NUM_DISPLAY, 648//2, 486//2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "i = 0\n",
    "for sim, plane in train_dataset.unbatch():\n",
    "    preds[i] = model.predict(sim[np.newaxis])\n",
    "    ground_truths[i] = plane\n",
    "    sims[i] = np.squeeze(sim)\n",
    "    i += 1\n",
    "    if i == NUM_DISPLAY:\n",
    "        break\n",
    "        \n",
    "# assert(i == VAL_LENGTH)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print('Prediction time per sample:', (t1 - t0) / NUM_DISPLAY, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(30, 15 * NUM_DISPLAY))\n",
    "rows, columns = NUM_DISPLAY, 2\n",
    "for i in range(NUM_DISPLAY):\n",
    "    # Plot prediction\n",
    "    s = fig.add_subplot(rows, columns, columns*i+1)\n",
    "    s.set_title(\"prediction {0}\".format(i), size=20)\n",
    "    plt.imshow(np.clip(preds[i], 0, 1))\n",
    "    \n",
    "    # Plot ground truth\n",
    "    s = fig.add_subplot(rows, columns, columns*i+2)\n",
    "    s.set_title(\"ground truth {0}\".format(i), size=20)\n",
    "    plt.imshow(ground_truths[i])\n",
    "    \n",
    "plt.savefig(path.join(image_path, 'train_{}.pdf'.format(epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "i = 0\n",
    "for sim, plane in val_dataset.unbatch():\n",
    "    preds[i] = model.predict(sim[np.newaxis])\n",
    "    ground_truths[i] = plane\n",
    "    sims[i] = np.squeeze(sim)\n",
    "    i += 1\n",
    "    if i == NUM_DISPLAY:\n",
    "        break\n",
    "        \n",
    "# assert(i == VAL_LENGTH)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print('Prediction time per sample:', (t1 - t0) / NUM_DISPLAY, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(30, 15 * NUM_DISPLAY))\n",
    "rows, columns = NUM_DISPLAY, 2\n",
    "for i in range(NUM_DISPLAY):\n",
    "    # Plot prediction\n",
    "    s = fig.add_subplot(rows, columns, columns*i+1)\n",
    "    s.set_title(\"prediction {0}\".format(i), size=20)\n",
    "    plt.imshow(np.clip(preds[i], 0, 1))\n",
    "    \n",
    "    # Plot ground truth\n",
    "    s = fig.add_subplot(rows, columns, columns*i+2)\n",
    "    s.set_title(\"ground truth {0}\".format(i), size=20)\n",
    "    plt.imshow(ground_truths[i])\n",
    "    \n",
    "plt.savefig(path.join(image_path, 'validation_{}.pdf'.format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ground_truths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_unet",
   "language": "python",
   "name": "venv_unet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
